{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38c8be23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/danarapp/Desktop/energypattern-keyword-search\n"
     ]
    }
   ],
   "source": [
    "cd /Users/danarapp/Desktop/energypattern-keyword-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cf287e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from constants.abs_paths import AbsDirPath\n",
    "from pathlib import Path\n",
    "from processing_pipeline.utilities.data_transformation import load_all_files\n",
    "import openpyxl\n",
    "\n",
    "\n",
    "def display_and_save(df, path):\n",
    "    df.to_excel(path, merge_cells=False)\n",
    "    display(df)\n",
    "\n",
    "def display_and_save_csv(df, path):\n",
    "    df.to_csv(path)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ca057b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 files, [PosixPath('/Users/danarapp/Desktop/energypattern-keyword-search/data/keywords_2/pr_first_iteration/paperless-ngx.paperless-ngx.v2.18.4.pr_corpus.parquet'), PosixPath('/Users/danarapp/Desktop/energypattern-keyword-search/data/keywords_2/pr_first_iteration/saleor.saleor.3.21.19.pr_corpus.parquet'), PosixPath('/Users/danarapp/Desktop/energypattern-keyword-search/data/keywords_2/pr_first_iteration/netbox-community.netbox.v4.4.1.pr_corpus.parquet')]\n"
     ]
    }
   ],
   "source": [
    "base_dir = Path(AbsDirPath.PR_KEYWORDS_MATCHING)\n",
    "\n",
    "df_git = load_all_files(base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2871e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 files, [PosixPath('/Users/danarapp/Desktop/energypattern-keyword-search/data/keywords_2/second_testiteration/zulip.zulip.11.2.issue_comment.parquet'), PosixPath('/Users/danarapp/Desktop/energypattern-keyword-search/data/keywords_2/second_testiteration/netbox-community.netbox.v4.4.1.issue.parquet'), PosixPath('/Users/danarapp/Desktop/energypattern-keyword-search/data/keywords_2/second_testiteration/zulip.zulip.11.2.issue.parquet'), PosixPath('/Users/danarapp/Desktop/energypattern-keyword-search/data/keywords_2/second_testiteration/netbox-community.netbox.v4.4.1.release.parquet'), PosixPath('/Users/danarapp/Desktop/energypattern-keyword-search/data/keywords_2/second_testiteration/paperless-ngx.paperless-ngx.v2.18.4.issue.parquet'), PosixPath('/Users/danarapp/Desktop/energypattern-keyword-search/data/keywords_2/second_testiteration/saleor.saleor.3.21.19.issue.parquet'), PosixPath('/Users/danarapp/Desktop/energypattern-keyword-search/data/keywords_2/second_testiteration/saleor.saleor.3.21.19.release.parquet'), PosixPath('/Users/danarapp/Desktop/energypattern-keyword-search/data/keywords_2/second_testiteration/paperless-ngx.paperless-ngx.v2.18.4.issue_comment.parquet'), PosixPath('/Users/danarapp/Desktop/energypattern-keyword-search/data/keywords_2/second_testiteration/saleor.saleor.3.21.19.issue_comment.parquet'), PosixPath('/Users/danarapp/Desktop/energypattern-keyword-search/data/keywords_2/second_testiteration/netbox-community.netbox.v4.4.1.issue_comment.parquet')]\n",
      "Loaded 6 files, [PosixPath('/Users/danarapp/Desktop/energypattern-keyword-search/data/keywords_2/second_testiteration/full/zulip.zulip.11.2.docs.parquet'), PosixPath('/Users/danarapp/Desktop/energypattern-keyword-search/data/keywords_2/second_testiteration/full/zulip.zulip.11.2.code_comment.parquet'), PosixPath('/Users/danarapp/Desktop/energypattern-keyword-search/data/keywords_2/second_testiteration/full/saleor.saleor.3.21.19.code_comment.parquet'), PosixPath('/Users/danarapp/Desktop/energypattern-keyword-search/data/keywords_2/second_testiteration/full/netbox-community.netbox.v4.4.1.docs.parquet'), PosixPath('/Users/danarapp/Desktop/energypattern-keyword-search/data/keywords_2/second_testiteration/full/paperless-ngx.paperless-ngx.v2.18.4.code_comment.parquet'), PosixPath('/Users/danarapp/Desktop/energypattern-keyword-search/data/keywords_2/second_testiteration/full/netbox-community.netbox.v4.4.1.code_comment.parquet')]\n"
     ]
    }
   ],
   "source": [
    "base_dir = Path(AbsDirPath.SECOND_KEYWORDS_MATCHING)\n",
    "full_dir = base_dir / \"full\"\n",
    "\n",
    "df_git = load_all_files(base_dir)\n",
    "df_comments = load_all_files(full_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f6e180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For datatransfer\n",
    "df_git_datatransfer = df_git[df_git[\"qa\"] == \"datatransfer\"]\n",
    "df_comments_datatransfer = df_comments[df_comments[\"qa\"] == \"datatransfer\"]\n",
    "\n",
    "# For UI\n",
    "df_git_ui = df_git[df_git[\"qa\"] == \"UI\"]\n",
    "df_comments_ui = df_comments[df_comments[\"qa\"] == \"UI\"]\n",
    "\n",
    "# Filter for code_optimization\n",
    "df_git_codeopt = df_git[df_git[\"qa\"] == \"code_optimization\"]\n",
    "df_comments_codeopt = df_comments[df_comments[\"qa\"] == \"code_optimization\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8202f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dedupe] Removed 41 duplicates (from 121 → 80) in dfs[0]\n",
      "[dedupe] Removed 0 duplicates (from 8 → 8) in dfs[1]\n",
      "[dedupe] Removed 32 duplicates (from 103 → 71) in dfs[2]\n"
     ]
    }
   ],
   "source": [
    "excel_filename = \"pr_first_iteration.xlsx\"  # change as needed\n",
    "out_dir = Path(\"/Users/danarapp/Desktop/energypattern-keyword-search/processing_pipeline/analysis/analyzed_matches\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_path = out_dir / excel_filename\n",
    "\n",
    "# Explicit list of DataFrames to export\n",
    "dfs = [\n",
    "    df_git_datatransfer,\n",
    "    df_comments_datatransfer,\n",
    "    df_git_ui,\n",
    "    df_comments_ui,\n",
    "    df_git_codeopt,\n",
    "    df_comments_codeopt,\n",
    "]\n",
    "\n",
    "# Deduplicate each df in-place (by url + matched_word) and report removals\n",
    "for i, df in enumerate(dfs):\n",
    "    before = len(df)\n",
    "    deduped = df.drop_duplicates(subset=[\"url\", \"matched_word\"], keep=\"first\").copy()\n",
    "    removed = before - len(deduped)\n",
    "    dfs[i] = deduped\n",
    "    print(f\"[dedupe] Removed {removed} duplicates (from {before} → {len(deduped)}) in dfs[{i}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "817cd7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Counts (deduplicated) ===\n",
      "datatransfer - git: 437, comments: 83\n",
      "UI           - git: 28, comments: 8\n",
      "code_opt     - git: 146, comments: 33\n",
      "----\n",
      "TOTAL git: 611\n",
      "TOTAL comments: 124\n"
     ]
    }
   ],
   "source": [
    "# Count deduplicated matches\n",
    "count_git_datatransfer = len(dfs[0])\n",
    "count_comments_datatransfer = len(dfs[1])\n",
    "count_git_ui = len(dfs[2])\n",
    "count_comments_ui = len(dfs[3])\n",
    "count_git_codeopt = len(dfs[4])\n",
    "count_comments_codeopt = len(dfs[5])\n",
    "\n",
    "# Totals\n",
    "total_git = count_git_datatransfer + count_git_ui + count_git_codeopt\n",
    "total_comments = count_comments_datatransfer + count_comments_ui + count_comments_codeopt\n",
    "\n",
    "print(\"\\n=== Counts (deduplicated) ===\")\n",
    "print(f\"datatransfer - git: {count_git_datatransfer}, comments: {count_comments_datatransfer}\")\n",
    "print(f\"UI           - git: {count_git_ui}, comments: {count_comments_ui}\")\n",
    "print(f\"code_opt     - git: {count_git_codeopt}, comments: {count_comments_codeopt}\")\n",
    "print(\"----\")\n",
    "print(f\"TOTAL git: {total_git}\")\n",
    "print(f\"TOTAL comments: {total_comments}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c415640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved review workbook to: /Users/danarapp/Desktop/energypattern-keyword-search/processing_pipeline/analysis/analyzed_matches/pr_first_iteration.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Columns to include in the Excel (includes new columns)\n",
    "review_cols = [\"row_id\", \"matched_word\", \"sentence\", \"source\", \"url\", \"pattern\", \"commit_url\", \"comment\"]\n",
    "\n",
    "# ==============================\n",
    "# Helpers\n",
    "# ==============================\n",
    "def excel_hyperlink_formula(url: str) -> str:\n",
    "    \"\"\"Return an Excel HYPERLINK() formula that shows the raw URL text and is clickable.\"\"\"\n",
    "    if not isinstance(url, str) or not url.strip():\n",
    "        return \"\"\n",
    "    safe = url.replace('\"', '\"\"')\n",
    "    return f'=HYPERLINK(\"{safe}\", \"{safe}\")'\n",
    "\n",
    "def ensure_schema(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Ensure required columns exist and add row_id (original index).\"\"\"\n",
    "    d = df.copy()\n",
    "    if \"pattern\" not in d.columns:\n",
    "        d[\"pattern\"] = \"\"           # default empty\n",
    "    if \"url\" not in d.columns:\n",
    "        d[\"url\"] = \"\"\n",
    "    if \"commit_url\" not in d.columns:\n",
    "        d[\"commit_url\"] = \"\"        # new column\n",
    "    if \"comment\" not in d.columns:\n",
    "        d[\"comment\"] = \"\"           # new column\n",
    "    d[\"row_id\"] = d.index           # keep original index for traceability\n",
    "    return d\n",
    "\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Write Excel with multiple sheets (fixed sheet names)\n",
    "# ==============================\n",
    "names = [\n",
    "    \"git_datatransfer\",\n",
    "    \"comments_datatransfer\",\n",
    "    \"git_UI\",\n",
    "    \"comments_UI\",\n",
    "    \"git_code_optimization\",\n",
    "    \"comments_code_optimization\",\n",
    "]\n",
    "\n",
    "with pd.ExcelWriter(out_path, engine=\"openpyxl\") as writer:\n",
    "    for name, df in zip(names, dfs):\n",
    "        dfx = ensure_schema(df)\n",
    "        out = dfx.reindex(columns=review_cols)\n",
    "\n",
    "        # Make both URL columns clickable with raw URL as text\n",
    "        out[\"url\"] = out[\"url\"].apply(excel_hyperlink_formula)\n",
    "        out[\"commit_url\"] = out[\"commit_url\"].apply(excel_hyperlink_formula)\n",
    "\n",
    "        # Write sheet with explicit, unique name\n",
    "        out.to_excel(writer, sheet_name=name, index=False)\n",
    "\n",
    "        # Freeze header row\n",
    "        ws = writer.sheets[name]\n",
    "        ws.freeze_panes = \"A2\"\n",
    "\n",
    "print(f\"Saved review workbook to: {out_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
